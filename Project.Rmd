---
title: "Barbell lifts prediction"
author: "Gil Huesca"
date: "9/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(randomForest)
```

## Introduction

One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to create a model to predict how well a persone perform barbell lifts.

The training data for this project are available here: [training data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)

The test data are available here: [test data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

For more information about the dataset and its project, you can consult the document in 

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013

or this [link](http://groupware.les.inf.puc-rio.br/har).

## Data preparation

Training and test sets are read from file in this section. Also they are prepared according to the following elements:

- The sets include values as NA, #DIV/0! and the empty string. Those are transformed in NA values.
- The first 7 columns ae general identification values that are not interesting for the purpose of this project. Those columns are taken out from both sets.
- There are columns that posses NA values, so they have incomplete information. These columns are taken out from both sets.

```{r}
trainSet <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
trainSet <- trainSet[,-(1:7)]

testSet <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
testSet <- testSet[,-(1:7)]

aux <- c(which(apply(is.na(trainSet), 2, any)),which(apply(is.na(testSet), 2, any)))

trainSet <- trainSet[,-aux]
testSet <- testSet[,-aux]

```

## Model fitting

Before the model creation process, we want to know if there is any variable that has a variance near to zero. That kind of variance will not be useful for our prediction model because they have little change accross observations.

```{r}
zeroVar <- nearZeroVar(trainSet)
zeroVar

seed <- 399
```

The result is an empty set, this means that after the data preparation process we don't have this type of variables.

We proceed then to the fitting of the model. We will use a general (`r seed`) seed for reproducibility purposes. After that we will partition the training data to have a validation set for cross validation purposes. We will use a 70% of the data as training set and a 30% of the data as validation set.

```{r}
set.seed(seed)
partition <- createDataPartition(trainSet$classe, p=0.7, list=FALSE)
training <- trainSet[partition,]
validation <- trainSet[-partition,]
```

We will use a random forest algorithm with the classe variable as output and all other variables as predictors. We expect an out of sample error not grater than 1%.

```{r}
training$classe <- as.factor(training$classe)
fit <- randomForest(classe ~ ., data = training)

fit
```

## Model validation

We will apply this model to the validation set in order to measure its accuracy.

```{r}
resultsValidation <- predict(fit, newdata=validation)
matrix <- confusionMatrix(as.factor(validation$classe), resultsValidation)

matrix
```

As we can see, the accuracy for this model applied to the validation set is `r matrix$overall[1]`. According to this the overall out of sample error is `r 1-matrix$overall[1]`.

## Applying model to test set

The results for the model applied to the test set are the following.

```{r}
resultsTest <- predict(fit, newdata=testSet)
resultsTest
```